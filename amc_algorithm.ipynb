{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data\n",
      "finished\n"
     ]
    }
   ],
   "source": [
    "from algorithm_module import start_amc\n",
    "\n",
    "samples, labels, snr, feature_list = start_amc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step_by_step(samples,labels,snr,tree_depth):\n",
    "    \n",
    "    all_feats = [i for i in range(len(samples[1]))]\n",
    "    # feats1 = [5,6,7,8,9,10]\n",
    "    split1 = ['AM-SSB-SC','4ASK','OOK']\n",
    "    classifier1,mask1 = split_classification(samples,labels,snr,all_feats,'Split Step 1',split1,tree_depth)\n",
    "\n",
    "    temp_labels = labels[~mask1]\n",
    "    samples2 = samples[~mask1]\n",
    "    snr_temp = snr[~mask1]\n",
    "    split2 = ['GMSK','AM-DSB-SC','BPSK','FM']\n",
    "    classifier2,mask2 = split_classification(samples2,temp_labels,snr_temp,all_feats,'Split Step 2',split2,tree_depth)\n",
    "\n",
    "    temp_labels = labels[~mask1][~mask2]\n",
    "    samples3 = samples2[~mask2]\n",
    "    snr_temp = snr_temp[~mask2]\n",
    "    split3 = ['16QAM','8PSK','QPSK','OQPSK']\n",
    "    classifier3,mask3 = split_classification(samples3,temp_labels,snr_temp,all_feats,'Split Step 3',split3,tree_depth)\n",
    "    \n",
    "    detection_per_label_steps(samples, labels, snr, 'Full Split',classifier1,classifier2,classifier3)\n",
    "    # classification per SNR\n",
    "    unique_snr = np.unique(snr)\n",
    "    unique_labels = np.unique(labels)\n",
    "    accuracy_list = []\n",
    "    for snr_val in unique_snr:\n",
    "        mask = snr == snr_val\n",
    "        x_snr = samples[mask]\n",
    "        y_snr = labels[mask]\n",
    "        final_labels = steps_tree(x_snr,classifier1,classifier2,classifier3)\n",
    "        accuracy_snr = accuracy_score(y_snr, final_labels)\n",
    "        accuracy_list.append(accuracy_snr)\n",
    "        if snr_val in range(11):\n",
    "            cm = confusion_matrix(y_snr, final_labels, labels=unique_labels)\n",
    "            plt.figure(figsize=(8, 6))\n",
    "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=unique_labels, yticklabels=unique_labels)\n",
    "            plt.xlabel(\"Predicted Labels\")\n",
    "            plt.ylabel(\"True Labels\")\n",
    "            plt.title(f\"Confusion Matrix for SNR={snr_val}dB, Acc={accuracy_snr}%\")\n",
    "            file_path = f\"confusion_matrix_SNR={snr_val}.png\"\n",
    "            plt.savefig(file_path)\n",
    "            plt.clf()\n",
    "            plt.close()\n",
    "    accuracy_steps  = {\"snr\": unique_snr, \"accuracy\": accuracy_list, \"name\": 'Steps Classification'}\n",
    "    return accuracy_steps\n",
    "\n",
    "def split_classification(samples,labels,snr,feats,name,group,tree_depth):\n",
    "    \n",
    "    mask = np.isin(labels,group)\n",
    "    labels_temp = labels.copy()\n",
    "    if group:\n",
    "        labels_temp[~mask]='others'\n",
    "    samples_fix = samples[:,feats]\n",
    "    train_tresh = 2\n",
    "    accuracy_data, classifier = init_classification(samples_fix, labels_temp, snr, name, train_tresh, tree_depth)\n",
    "    return classifier,mask\n",
    "\n",
    "def init_classification(samples, labels, snr, name, train_tresh, tree_depth):\n",
    "    # get the accuracy graph per SNR and per label\n",
    "    labeling = f\"Train set SNR>{train_tresh}dB, {name}\"\n",
    "    if train_tresh<0:\n",
    "        labeling = f\"Full Train set, {name}\"\n",
    "    x_train, x_test, y_train, y_test,snr_test = data_spliting(samples, labels, snr, train_tresh)\n",
    "    classifier = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    classifier.fit(x_train, y_train)\n",
    "    # print(classifier.get_depth())\n",
    "    try:\n",
    "        os.mkdir(labeling)\n",
    "    except FileExistsError:\n",
    "        print('skip creation')\n",
    "    print(\"Classify per SNR\")\n",
    "    accuracy_data = detection_per_snr(x_test, y_test, snr_test, classifier, labeling)\n",
    "    # accuracy_data =1\n",
    "    print(\"Classify per Label\")\n",
    "    detection_per_label(x_test, y_test, snr_test, classifier, labeling)\n",
    "    \n",
    "    return accuracy_data,classifier\n",
    "\n",
    "def data_spliting(samples, labels ,snr , train_tresh):\n",
    "    # split data for training using only high SNR\n",
    "    if train_tresh>0:\n",
    "        mask = snr>train_tresh\n",
    "        samples_mask = samples[mask]\n",
    "        labels_mask = labels[mask]\n",
    "        snr_mask = snr[mask]\n",
    "        samples_not = samples[~mask]\n",
    "        labels_not = labels[~mask]\n",
    "        x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        samples_mask,\n",
    "        labels_mask,\n",
    "        range(len(samples_mask)),\n",
    "        test_size=0.2,\n",
    "        random_state=40,\n",
    "        stratify=labels_mask,\n",
    "    )\n",
    "        x_test=np.concatenate((x_test,samples_not))\n",
    "        y_test=np.concatenate((y_test,labels_not))\n",
    "        snr_test = np.concatenate((snr_mask[test_indices],snr[~mask]))\n",
    "    else:\n",
    "        x_train, x_test, y_train, y_test, train_indices, test_indices = train_test_split(\n",
    "        samples,\n",
    "        labels,\n",
    "        range(len(samples)),\n",
    "        test_size=0.2,\n",
    "        random_state=41,\n",
    "        stratify=labels,\n",
    "    )\n",
    "        snr_test = snr[test_indices]\n",
    "    return x_train, x_test, y_train, y_test,snr_test\n",
    "\n",
    "def detection_per_snr(x_test, y_test, snr_test, classifier, name):\n",
    "    # classification per SNR\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    accuracy_list = []\n",
    "    for snr_val in unique_snr:\n",
    "        mask = snr_test == snr_val\n",
    "        x_snr = x_test[mask]\n",
    "        y_snr = y_test[mask]\n",
    "        y_pred_snr = classifier.predict(x_snr)\n",
    "        accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "        accuracy_list.append(accuracy_snr)\n",
    "        if snr_val in range(11):\n",
    "            plot_confusion_matrix(y_snr, y_pred_snr, np.unique(y_snr), snr_val, name)\n",
    "    return {\"snr\": unique_snr, \"accuracy\": accuracy_list, \"name\": name}\n",
    "\n",
    "def detection_per_label(x_test, y_test, snr_test, classifier, name):\n",
    "    # classify per label\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    unique_label = np.unique(y_test)\n",
    "    i=1\n",
    "    num_plots = i  # Number of plots needed\n",
    "    fig, axs = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 6 * num_plots))\n",
    "    axs.set_title(f\"Accuracy vs SNR\")\n",
    "    for label in unique_label:\n",
    "        if label =='others':\n",
    "            continue\n",
    "        mask = y_test == label\n",
    "        x_label = x_test[mask]\n",
    "        y_label = y_test[mask]\n",
    "        snr_label = snr_test[mask]\n",
    "        accuracy_list = []\n",
    "        for snr_val in unique_snr:\n",
    "            mask_snr = snr_label == snr_val\n",
    "            x_snr = x_label[mask_snr]\n",
    "            y_snr = y_label[mask_snr]\n",
    "            y_pred_snr = classifier.predict(x_snr)\n",
    "            accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "            accuracy_list.append(accuracy_snr)\n",
    "        axs.plot(unique_snr, accuracy_list, label=label)\n",
    "    axs.set_xlabel(\"SNR\")\n",
    "    axs.set_ylabel(\"Accuracy\")\n",
    "    axs.legend()\n",
    "    axs.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    axs.xaxis.set_major_locator(MultipleLocator(2))\n",
    "    axs.grid(which='major')\n",
    "    plt.tight_layout()\n",
    "    file_path = os.path.join(name, f\"label_group_accuracy_{name}.png\")\n",
    "    plt.savefig(file_path)\n",
    "    print(\"saved plots\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def detection_per_label_steps(x_test, y_test, snr_test, name,classifier1,classifier2,classifier3):\n",
    "    group1 = ['AM-DSB-SC','AM-SSB-SC','FM','GMSK','OQPSK']\n",
    "    group2 = ['OOK','4ASK','BPSK','QPSK','8PSK','16QAM']\n",
    "    groups = [group1, group2]   \n",
    "    # classify per label\n",
    "    unique_snr = np.unique(snr_test)\n",
    "    num_plots = len(groups)  # Number of plots needed\n",
    "    fig, axs = plt.subplots(nrows=num_plots, ncols=1, figsize=(10, 6 * num_plots))\n",
    "    for i, label_group in enumerate(groups):\n",
    "        axs[i].set_title(f\"Accuracy vs SNR for Label Group {i+1}\")\n",
    "        for label in label_group:\n",
    "            mask = y_test == label\n",
    "            x_label = x_test[mask]\n",
    "            y_label = y_test[mask]\n",
    "            snr_label = snr_test[mask]\n",
    "            accuracy_list = []\n",
    "            for snr_val in unique_snr:\n",
    "                mask_snr = snr_label == snr_val\n",
    "                x_snr = x_label[mask_snr]\n",
    "                y_snr = y_label[mask_snr]\n",
    "                try:\n",
    "                    y_pred_snr = steps_tree(x_snr,classifier1,classifier2,classifier3)\n",
    "                except:\n",
    "                    print('help')\n",
    "                    print('error')\n",
    "                accuracy_snr = accuracy_score(y_snr, y_pred_snr)\n",
    "                accuracy_list.append(accuracy_snr)\n",
    "            axs[i].plot(unique_snr, accuracy_list, label=label)\n",
    "        axs[i].set_xlabel(\"SNR\")\n",
    "        axs[i].set_ylabel(\"Accuracy\")\n",
    "        axs[i].legend()\n",
    "        axs[i].yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "        axs[i].xaxis.set_major_locator(MultipleLocator(2))\n",
    "        axs[i].grid(which='major')\n",
    "    plt.tight_layout()\n",
    "    file_path =  f\"label_group_accuracy_{name}.png\"\n",
    "    plt.savefig(file_path)\n",
    "    print(\"saved plots\")\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, labels, snr, name):\n",
    "    # plot confusion matrix for the data\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=labels, yticklabels=labels)\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.title(f\"Confusion Matrix for SNR={snr}dB, Acc={accuracy}%\")\n",
    "    file_path = os.path.join(name, f\"SNR={snr}.png\")\n",
    "    plt.savefig(file_path)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def combine_accuracy_graphs(*args):\n",
    "    \n",
    "    # linestyles = ['-', '--',':']  # Different linestyles for each scenario\n",
    "    linestyles = ['-']\n",
    "    markes = ['o','s','^','x','*','+']\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, accuracy_data in enumerate(args):\n",
    "        linestyle = linestyles[i % len(linestyles)]\n",
    "        marker = markes[i % len(markes)]\n",
    "        ax.plot(\n",
    "            accuracy_data[\"snr\"], accuracy_data[\"accuracy\"],\n",
    "            linestyle=linestyle, linewidth=1, marker=marker, markersize=4, label=accuracy_data[\"name\"]\n",
    "        )\n",
    "    ax.set_xlabel(\"SNR\")\n",
    "    ax.set_ylabel(\"Accuracy\")\n",
    "    ax.set_title(\"Accuracy vs SNR\")\n",
    "    ax.legend()\n",
    "    ax.yaxis.set_major_locator(MultipleLocator(0.1))\n",
    "    ax.xaxis.set_major_locator(MultipleLocator(4))\n",
    "    ax.grid(which='major')\n",
    "    num_files_saved = sum(1 for file in os.listdir('.') if file.startswith('combine_accuracy_graph_'))\n",
    "    file_path = f'combine_accuracy_graph_{num_files_saved + 1}.png'\n",
    "    plt.savefig(file_path)\n",
    "    plt.clf()\n",
    "    plt.close()\n",
    "\n",
    "def steps_tree(X,classifier1,classifier2,classifier3):\n",
    "# Step 1: Initial classification into 4 labels, one of them is \"others\"\n",
    "    labels_step1 = classifier1.predict(X)\n",
    "\n",
    "    # Step 2: Identify \"others\" samples from Step 1 and classify them into 4 labels, one of them is \"others\"\n",
    "    X_others_step2 = X[labels_step1 == \"others\"]\n",
    "    if len(X_others_step2)>0:\n",
    "        labels_step2 = classifier2.predict(X_others_step2)\n",
    "        X_others_step3 = X_others_step2[labels_step2 == \"others\"]\n",
    "        if len(X_others_step3)>0:     \n",
    "            labels_step3 = classifier3.predict(X_others_step3)\n",
    "        else:\n",
    "            labels_step3 = 'good'\n",
    "    else:\n",
    "        labels_step2='good'\n",
    "        labels_step3 = 'good'\n",
    "\n",
    "    # Step 3: Identify \"others\" samples from Step 2 and classify them into 5 labels\n",
    "            \n",
    "\n",
    "    # Combine the labels from Steps 1, 2, and 3 into the final labels\n",
    "    final_labels = []\n",
    "    current_index_step2 = 0\n",
    "    current_index_step3 = 0\n",
    "\n",
    "    for label in labels_step1:\n",
    "        if label == \"others\":\n",
    "            if labels_step2[current_index_step2] == \"others\":\n",
    "                final_labels.append(labels_step3[current_index_step3])\n",
    "                current_index_step3 += 1\n",
    "            else:\n",
    "                final_labels.append(labels_step2[current_index_step2])\n",
    "            current_index_step2 += 1\n",
    "        else:\n",
    "            final_labels.append(label)\n",
    "\n",
    "    # Now 'final_labels' contains the final classification of all samples\n",
    "\n",
    "    # Now 'final_labels' contains the final classification of all samples\n",
    "    return final_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # First Test - Get the minmimal tree depth\n",
    "acc1,classifier = init_classification(samples, labels, snr, \"Tree depth=4\", -1, 4)\n",
    "acc2,classifier = init_classification(samples, labels, snr, \"Tree depth=6\", -1, 6)\n",
    "acc3,classifier = init_classification(samples, labels, snr, \"Tree depth=8\", -1, 8)\n",
    "acc4,classifier = init_classification(samples, labels, snr, \"Tree depth=10\", -1, 10)\n",
    "acc5,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", -1, 20)\n",
    "acc6,classifier = init_classification(samples, labels, snr, \"Tree depth=50\", -1, 50)\n",
    "\n",
    "combine_accuracy_graphs(acc1,acc2,acc3,acc4,acc5,acc6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skip creation\n",
      "Classify per SNR\n",
      "Classify per Label\n",
      "saved plots\n",
      "Classify per SNR\n",
      "Classify per Label\n",
      "saved plots\n",
      "Classify per SNR\n",
      "Classify per Label\n",
      "saved plots\n",
      "Classify per SNR\n",
      "Classify per Label\n",
      "saved plots\n",
      "Classify per SNR\n",
      "Classify per Label\n",
      "saved plots\n"
     ]
    }
   ],
   "source": [
    "# Second Test - Get the best SNR threshold for the training set\n",
    "accuracy_train1,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", -1, 20)\n",
    "accuracy_train2,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", 1, 20)\n",
    "accuracy_train3,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", 5, 20)\n",
    "accuracy_train4,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", 10, 20)\n",
    "accuracy_train5,classifier = init_classification(samples, labels, snr, \"Tree depth=20\", 20, 20)\n",
    "\n",
    "combine_accuracy_graphs(accuracy_train1, accuracy_train2, accuracy_train3, accuracy_train4, accuracy_train5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# third test - PCA possibility\n",
    "from sklearn.decomposition import PCA\n",
    "accuracy_list = []\n",
    "for pp in [5,10,15,20]:\n",
    "    pca = PCA(n_components=pp)\n",
    "    pca.fit(np.log10(samples))\n",
    "    principalComponents = pca.fit_transform(np.log10(samples))\n",
    "    accuracy_train,classifier = init_classification(principalComponents, labels, snr, f\" PCA for {pp} components\", 20, 7)\n",
    "    accuracy_list.append(accuracy_train)\n",
    "    \n",
    "accuracy_train,classifier = init_classification(np.log10(samples), labels, snr, f\"No PCA\", 20, 7)\n",
    "accuracy_list.append(accuracy_train)\n",
    "combine_accuracy_graphs(accuracy_list[0], accuracy_list[1], accuracy_list[2] ,accuracy_list[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"we are here\")\n",
    "train_tresh = 1\n",
    "tree_depth = 3\n",
    "# samples_fix = samples[:,feats]\n",
    "# regular tree classifiers\n",
    "print(\"classification for cumulants...\")\n",
    "accuracy_data0,classifier = init_classification(samples[:,range(8)], labels, snr, \"cumulants\", train_tresh, tree_depth)\n",
    "accuracy_data1,classifier = init_classification(samples[:,range(14)], labels, snr, \"cumulants with dx\", train_tresh, tree_depth)\n",
    "accuracy_data2,classifier = init_classification(samples, labels, snr, \"cumulants, dx, IQ and phase\", train_tresh, tree_depth)\n",
    "accuracy_steps = step_by_step(samples, labels, snr, tree_depth)\n",
    "\n",
    "combine_accuracy_graphs(accuracy_data0,accuracy_data1,accuracy_data2,accuracy_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_feats = [i for i in range(len(samples[1]))]\n",
    "tree_depth = 3\n",
    "feats =[list(range(8))+list(range(14,25))] \n",
    "feats = feats[0]\n",
    "split1 = ['AM-SSB-SC','4ASK','OOK']\n",
    "classifier1,mask1 = split_classification(samples,labels,snr,feats,'split_1',split1,tree_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DNN classifier\n",
    "# import tensorflow as tf\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# model = models.Sequential()\n",
    "# model.add(layers.Dense(16, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "# model.add(layers.Dense(8, activation='relu'))\n",
    "# model.add(layers.Dense(np.unique(y_train).shape[0], activation='softmax'))\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=1, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # SVM classifier\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# svm_classifier = SVC(kernel='linear', C=1.0)  # You can use other kernels as well\n",
    "# print('fitting')\n",
    "# svm_classifier.fit(X_train, y_train)\n",
    "# print('predict')\n",
    "# y_pred = svm_classifier.predict(X_test)\n",
    "# # Calculate the accuracy of the model\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
